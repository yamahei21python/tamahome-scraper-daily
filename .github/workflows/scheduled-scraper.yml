name: Scheduled TamaHome Scraper

on:
  schedule:
    # UTCで毎日午前0時30分に実行 (日本時間だと午前9時30分)
    - cron: '30 0 * * *'
  workflow_dispatch:

jobs:
  scrape-and-compare-data:
    runs-on: ubuntu-latest

    steps:
      - name: リポジトリをチェックアウト
        uses: actions/checkout@v4

      - name: 前回のデータをダウンロード (比較用)
        uses: actions/download-artifact@v4
        with:
          name: tamahome-data-and-reports # 前回のupload-artifactで指定したartifactの名前
          path: ./TamaHome_CSV_Data/    # ダウンロード先のパス (スクリプトが期待するパス)

      - name: Python環境をセットアップ
        uses: actions/setup-python@v5
        with:
          python-version: '3.9' # Python 3.9以上を推奨 (ZoneInfoなどのため)

      - name: 依存関係をインストール
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: 物件スクレイピングスクリプトを実行 (your_script.py)
        run: python your_script.py

      - name: 物件比較分析スクリプトを実行 (compare_and_report.py)
        run: python compare_and_report.py

      - name: 営業所スクレイピングスクリプトを実行 (scrape_offices.py)
        run: python scrape_offices.py

      - name: 分析グラフ生成スクリプトを実行 (analyze_and_graph.py) # 新しいステップを追加
        run: python analyze_and_graph.py

      - name: 生成された全ファイル（CSV, TXT, PNG, PDF）をアーティファクトとして保存
        uses: actions/upload-artifact@v4
        with:
          name: tamahome-data-and-reports-${{ github.run_id }} # アーティファクト名を変更
          path: ./TamaHome_CSV_Data/ # 全てのファイルがこのパスに保存されることを想定
          retention-days: 7
