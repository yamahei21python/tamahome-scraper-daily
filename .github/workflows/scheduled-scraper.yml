name: Scheduled TamaHome Scraper

on:
  schedule:
    # UTCで毎日午前0時30分に実行 (日本時間だと午前9時30分)
    # GitHub ActionsのcronはUTCで評価されます。
    # 実行頻度を調整したい場合はこの部分を変更してください。
    - cron: '30 0 * * *'
  # GitHubのActionsタブから手動でワークフローを実行したい場合
  workflow_dispatch:

jobs:
  scrape-and-compare-data: # ジョブ名をより分かりやすく変更
    runs-on: ubuntu-latest # Ubuntu環境で実行

    steps:
      - name: リポジトリをチェックアウト
        uses: actions/checkout@v4 # リポジトリのコードをワークフローの実行環境にクローン

      - name: Python環境をセットアップ
        uses: actions/setup-python@v5
        with:
          python-version: '3.9' # スクリプトでZoneInfoを使用しているためPython 3.9以上を推奨

      - name: 依存関係をインストール
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt # requirements.txtに記述されたライブラリをインストール

      - name: スクレイピングスクリプトを実行 (your_script.py)
        run: python your_script.py # 最初のスクリプトを実行

      - name: 比較分析スクリプトを実行 (compare_and_report.py)
        # 比較スクリプトは前のスクリプトで生成されたファイルに依存するため、続けて実行
        run: python compare_and_report.py

      - name: 生成されたCSVファイルとレポートをアーティファクトとして保存
        uses: actions/upload-artifact@v4
        with:
          name: tamahome-data-and-reports-${{ github.run_id }} # アーティファクト名を変更
          path: ./TamaHome_CSV_Data/ # スクレイピングと比較スクリプトの両方で指定した保存パス
          retention-days: 7 # アーティファクトの保存期間 (任意)
