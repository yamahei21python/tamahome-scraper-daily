# app.py
import streamlit as st
import requests
import zipfile
import io
import pandas as pd
from datetime import datetime
from PIL import Image

# --- å®šæ•°è¨­å®š ---
GITHUB_API_URL = "https://api.github.com"
REPO_OWNER = "yamahei21python" 
REPO_NAME = "tamahome-scraper-daily"

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â˜…â˜…â˜… ã“ã“ã‚’ä¿®æ­£: å®Ÿéš›ã«ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã‚‹ â˜…â˜…â˜…
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
WORKFLOW_FILENAME = "scheduled-scraper.yml" 
ARTIFACT_NAME = "daily-analysis-report" 

try:
    GITHUB_TOKEN = st.secrets["github"]["token"]
except (KeyError, FileNotFoundError):
    import os
    GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")

HEADERS = {
    "Accept": "application/vnd.github.v3+json",
    "Authorization": f"token {GITHUB_TOKEN}",
}

st.set_page_config(page_title="ã‚¿ãƒãƒ›ãƒ¼ãƒ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ", layout="wide")
st.title("ğŸ“Š ã‚¿ãƒãƒ›ãƒ¼ãƒ  æ—¥æ¬¡åˆ†æãƒ¬ãƒãƒ¼ãƒˆãƒ“ãƒ¥ãƒ¼ã‚¢")

# --- é–¢æ•°å®šç¾© ---
@st.cache_data(ttl=86400)
def get_workflow_id_by_filename(filename: str) -> int:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼IDã‚’å–å¾—ã™ã‚‹"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/workflows"
    response = requests.get(url, headers=HEADERS)
    response.raise_for_status()
    workflows = response.json()["workflows"]
    for wf in workflows:
        if wf["path"].endswith(filename):
            return wf["id"]
    raise ValueError(f"Workflow with filename '{filename}' not found.")

@st.cache_data(ttl=3600)
def get_workflow_runs(workflow_id: int):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œå±¥æ­´ã‚’å–å¾—ã™ã‚‹"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/workflows/{workflow_id}/runs"
    params = {"status": "success", "per_page": 30}
    response = requests.get(url, headers=HEADERS, params=params)
    response.raise_for_status()
    return response.json()["workflow_runs"]

@st.cache_data(ttl=3600)
def get_artifacts_for_run(run_id):
    """ç‰¹å®šã®å®Ÿè¡ŒIDã«ç´ã¥ãã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/runs/{run_id}/artifacts"
    response = requests.get(url, headers=HEADERS)
    response.raise_for_status()
    return response.json()["artifacts"]

@st.cache_data(ttl=86400)
def download_and_extract_images(artifact_url):
    """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹"""
    response = requests.get(artifact_url, headers=HEADERS, stream=True)
    response.raise_for_status()
    images = {}
    analysis_text = ""
    with zipfile.ZipFile(io.BytesIO(response.content)) as z:
        for filename in sorted(z.namelist()):
            if filename.lower().endswith(".png"):
                img_bytes = z.read(filename)
                images[filename] = Image.open(io.BytesIO(img_bytes))
            elif filename.lower().endswith(".txt"):
                analysis_text = z.read(filename).decode('utf-8')
    return images, analysis_text

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
if not GITHUB_TOKEN:
    st.error("GitHubã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
else:
    try:
        workflow_id = get_workflow_id_by_filename(WORKFLOW_FILENAME)
        runs = get_workflow_runs(workflow_id)
        
        if not runs:
            st.warning("æˆåŠŸã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            run_data = []
            for run in runs:
                run_artifacts = get_artifacts_for_run(run["id"])
                for artifact in run_artifacts:
                    if artifact["name"] == ARTIFACT_NAME and not artifact["expired"]:
                        run_data.append({
                            "display_name": f"{datetime.fromisoformat(run['created_at'].replace('Z', '+00:00')).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} (ID: {run['id']})",
                            "artifact_url": artifact["archive_download_url"]
                        })
                        break 
            
            if not run_data:
                st.warning(f"'{ARTIFACT_NAME}' ã¨ã„ã†åå‰ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                df_runs = pd.DataFrame(run_data)
                selected_run_display_name = st.selectbox(
                    "è¡¨ç¤ºã—ãŸã„ãƒ¬ãƒãƒ¼ãƒˆã®æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                    df_runs["display_name"]
                )
                
                if selected_run_display_name:
                    selected_artifact_url = df_runs[df_runs["display_name"] == selected_run_display_name].iloc[0]["artifact_url"]
                    
                    with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                        images, analysis_text = download_and_extract_images(selected_artifact_url)
                    
                    if images:
                        st.header("åˆ†æã‚°ãƒ©ãƒ•")
                        
                        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
                        for filename, img in images.items():
                            # ãƒ•ã‚¡ã‚¤ãƒ«åã§åˆ¤å®šã—ã¦è¡¨ç¤ºæ–¹æ³•ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
                            if filename.startswith("01_attribute_pie"):
                                # å††ã‚°ãƒ©ãƒ•ã®å ´åˆï¼š3åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§ä¸­å¤®æƒãˆï¼†ã‚µã‚¤ã‚ºèª¿æ•´
                                col1, col2, col3 = st.columns([1, 2, 1]) # çœŸã‚“ä¸­ã®åˆ—ã‚’åºƒãå–ã‚‹
                                with col2:
                                    st.image(img, caption=filename, use_column_width=True) # åˆ—ã®å¹…ã«åˆã‚ã›ã¦è¡¨ç¤º
                            else:
                                # ãã®ä»–ã®ã‚°ãƒ©ãƒ•ã®å ´åˆï¼šé€šå¸¸é€šã‚Šå…¨å¹…ã§è¡¨ç¤º
                                st.image(img, caption=filename, use_column_width=True)
                        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
                        
                        if analysis_text:
                            st.header("ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆåˆ†æçµæœ")
                            st.text(analysis_text)
                    else:
                        st.error("ãƒ¬ãƒãƒ¼ãƒˆç”»åƒã®å–å¾—ã¾ãŸã¯å±•é–‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
