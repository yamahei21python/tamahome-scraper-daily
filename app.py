# app.py
import streamlit as st
import requests
import zipfile
import io
import pandas as pd
from datetime import datetime

# --- å®šæ•°è¨­å®š ---
# ã“ã‚Œã‚‰ã¯ã‚ãªãŸã®ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¦ãã ã•ã„
GITHUB_API_URL = "https://api.github.com"
REPO_OWNER = "yamahei21python" # ã‚ãªãŸã®GitHubãƒ¦ãƒ¼ã‚¶ãƒ¼å
REPO_NAME = "tamahome-scraper-daily" # ã‚ãªãŸã®ãƒªãƒã‚¸ãƒˆãƒªå
WORKFLOW_NAME = "scheduled-run.yml" # ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å
ARTIFACT_NAME = "daily-analysis-report" # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå

# GitHub Personal Access Token (PAT) ã‚’Streamlitã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰å–å¾—
# ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ†ã‚¹ãƒˆã™ã‚‹å ´åˆã¯ã€ç’°å¢ƒå¤‰æ•°ã« GITHUB_TOKEN ã‚’è¨­å®šã—ã¦ãã ã•ã„
try:
    # Streamlit Community Cloudã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰èª­ã¿è¾¼ã¿
    GITHUB_TOKEN = st.secrets["github"]["token"]
except (KeyError, FileNotFoundError):
    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    import os
    GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")

# --- GitHub API ã¨é€šä¿¡ã™ã‚‹ãŸã‚ã®ãƒ˜ãƒƒãƒ€ãƒ¼ ---
HEADERS = {
    "Accept": "application/vnd.github.v3+json",
    "Authorization": f"token {GITHUB_TOKEN}",
}

# --- Streamlit ã‚¢ãƒ—ãƒªã®UIè¨­å®š ---
st.set_page_config(page_title="ã‚¿ãƒãƒ›ãƒ¼ãƒ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ", layout="wide")
st.title("ğŸ“Š ã‚¿ãƒãƒ›ãƒ¼ãƒ  æ—¥æ¬¡åˆ†æãƒ¬ãƒãƒ¼ãƒˆãƒ“ãƒ¥ãƒ¼ã‚¢")
st.markdown(f"ãƒªãƒã‚¸ãƒˆãƒª: [{REPO_OWNER}/{REPO_NAME}](https://github.com/{REPO_OWNER}/{REPO_NAME})")

# --- é–¢æ•°å®šç¾© ---

@st.cache_data(ttl=3600) # 1æ™‚é–“çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_workflow_runs():
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œå±¥æ­´ã‚’å–å¾—ã™ã‚‹"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/workflows/{WORKFLOW_NAME}/runs"
    params = {"status": "success"} # æˆåŠŸã—ãŸå®Ÿè¡Œã®ã¿ã‚’å–å¾—
    response = requests.get(url, headers=HEADERS, params=params)
    response.raise_for_status()
    return response.json()["workflow_runs"]

@st.cache_data(ttl=3600) # 1æ™‚é–“çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_artifacts_for_run(run_id):
    """ç‰¹å®šã®å®Ÿè¡ŒIDã«ç´ã¥ãã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/runs/{run_id}/artifacts"
    response = requests.get(url, headers=HEADERS)
    response.raise_for_status()
    return response.json()["artifacts"]

@st.cache_data(ttl=86400) # 1æ—¥çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def download_and_extract_pdf(artifact_url):
    """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ä¸­ã®PDFã‚’ãƒ¡ãƒ¢ãƒªä¸Šã§å±•é–‹ã™ã‚‹"""
    response = requests.get(artifact_url, headers=HEADERS, stream=True)
    response.raise_for_status()

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸzipãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªä¸Šã§é–‹ã
    with zipfile.ZipFile(io.BytesIO(response.content)) as z:
        # zipãƒ•ã‚¡ã‚¤ãƒ«å†…ã®æœ€åˆã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        for filename in z.namelist():
            if filename.lower().endswith(".pdf"):
                # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿”ã™
                return z.read(filename)
    return None

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

if not GITHUB_TOKEN:
    st.error("GitHubã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlitã®ã‚·ãƒ¼ã‚¯áƒ itã« `GITHUB_TOKEN` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
else:
    try:
        # 1. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œå±¥æ­´ã‚’å–å¾—
        runs = get_workflow_runs()
        
        if not runs:
            st.warning("æˆåŠŸã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            # 2. æ—¥ä»˜é¸æŠã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            run_data = []
            for run in runs:
                # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆåãŒä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’æ¢ã™
                run_artifacts = get_artifacts_for_run(run["id"])
                for artifact in run_artifacts:
                    if artifact["name"] == ARTIFACT_NAME:
                        run_data.append({
                            "display_name": f"{datetime.fromisoformat(run['created_at'].replace('Z', '+00:00')).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} (ID: {run['id']})",
                            "run_id": run["id"],
                            "artifact_url": artifact["archive_download_url"]
                        })
                        break # ä¸€è‡´ã™ã‚‹ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã£ãŸã‚‰æ¬¡ã®runã¸

            if not run_data:
                st.warning(f"'{ARTIFACT_NAME}' ã¨ã„ã†åå‰ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                df_runs = pd.DataFrame(run_data)

                # 3. ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã§è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã‚’é¸æŠ
                selected_run_display_name = st.selectbox(
                    "è¡¨ç¤ºã—ãŸã„ãƒ¬ãƒãƒ¼ãƒˆã®æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                    df_runs["display_name"]
                )
                
                if selected_run_display_name:
                    # 4. é¸æŠã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã®PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤º
                    selected_artifact_url = df_runs[df_runs["display_name"] == selected_run_display_name].iloc[0]["artifact_url"]
                    
                    with st.spinner("PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                        pdf_bytes = download_and_extract_pdf(selected_artifact_url)
                    
                    if pdf_bytes:
                        # Streamlitã®æ©Ÿèƒ½ã§PDFã‚’åŸ‹ã‚è¾¼ã¿è¡¨ç¤º
                        st.pdf(pdf_bytes, height=1000)
                    else:
                        st.error("PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã¾ãŸã¯å±•é–‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    except requests.exceptions.RequestException as e:
        st.error(f"GitHub APIã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
