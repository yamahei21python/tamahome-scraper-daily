# app.py
import streamlit as st
import requests
import zipfile
import io
import pandas as pd
from datetime import datetime

# â˜…â˜…â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°ç”¨ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ  â˜…â˜…â˜…â˜…â˜…
st.write(f"Streamlit version: {st.__version__}")
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

# --- å®šæ•°è¨­å®š ---
GITHUB_API_URL = "https://api.github.com"
REPO_OWNER = "yamahei21python" # ã‚ãªãŸã®GitHubãƒ¦ãƒ¼ã‚¶ãƒ¼å
REPO_NAME = "tamahome-scraper-daily" # ã‚ãªãŸã®ãƒªãƒã‚¸ãƒˆãƒªå

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â˜…â˜…â˜… ã“ã“ã‚’ä¿®æ­£: æ­£ã—ã„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›´ â˜…â˜…â˜…
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
WORKFLOW_FILENAME = "scheduled-scraper.yml" # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã‚‹
ARTIFACT_NAME = "daily-analysis-report" # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå

# GitHub Personal Access Token (PAT) ã‚’Streamlitã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰å–å¾—
try:
    GITHUB_TOKEN = st.secrets["github"]["token"]
except (KeyError, FileNotFoundError):
    import os
    GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")

# --- GitHub API ã¨é€šä¿¡ã™ã‚‹ãŸã‚ã®ãƒ˜ãƒƒãƒ€ãƒ¼ ---
HEADERS = {
    "Accept": "application/vnd.github.v3+json",
    "Authorization": f"token {GITHUB_TOKEN}",
}

# --- Streamlit ã‚¢ãƒ—ãƒªã®UIè¨­å®š ---
st.set_page_config(page_title="ã‚¿ãƒãƒ›ãƒ¼ãƒ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ", layout="wide")
st.title("ğŸ“Š ã‚¿ãƒãƒ›ãƒ¼ãƒ  æ—¥æ¬¡åˆ†æãƒ¬ãƒãƒ¼ãƒˆãƒ“ãƒ¥ãƒ¼ã‚¢")
st.markdown(f"ãƒªãƒã‚¸ãƒˆãƒª: [{REPO_OWNER}/{REPO_NAME}](https://github.com/{REPO_OWNER}/{REPO_NAME})")

# --- é–¢æ•°å®šç¾© ---

@st.cache_data(ttl=86400) # 1æ—¥ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_workflow_id_by_filename(filename: str) -> int:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼IDã‚’å–å¾—ã™ã‚‹"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/workflows"
    response = requests.get(url, headers=HEADERS)
    response.raise_for_status()
    workflows = response.json()["workflows"]
    for wf in workflows:
        if wf["path"].endswith(filename):
            return wf["id"]
    raise ValueError(f"Workflow with filename '{filename}' not found.")


@st.cache_data(ttl=3600) # 1æ™‚é–“çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_workflow_runs(workflow_id: int):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œå±¥æ­´ã‚’å–å¾—ã™ã‚‹"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/workflows/{workflow_id}/runs"
    params = {"status": "success", "per_page": 30} # æˆåŠŸã—ãŸå®Ÿè¡Œã‚’30ä»¶ã¾ã§å–å¾—
    response = requests.get(url, headers=HEADERS, params=params)
    response.raise_for_status()
    return response.json()["workflow_runs"]

@st.cache_data(ttl=3600) # 1æ™‚é–“çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_artifacts_for_run(run_id):
    """ç‰¹å®šã®å®Ÿè¡ŒIDã«ç´ã¥ãã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/runs/{run_id}/artifacts"
    response = requests.get(url, headers=HEADERS)
    response.raise_for_status()
    return response.json()["artifacts"]

@st.cache_data(ttl=86400) # 1æ—¥çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def download_and_extract_pdf(artifact_url):
    """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ä¸­ã®PDFã‚’ãƒ¡ãƒ¢ãƒªä¸Šã§å±•é–‹ã™ã‚‹"""
    response = requests.get(artifact_url, headers=HEADERS, stream=True)
    response.raise_for_status()

    with zipfile.ZipFile(io.BytesIO(response.content)) as z:
        for filename in z.namelist():
            if filename.lower().endswith(".pdf"):
                return z.read(filename)
    return None

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

if not GITHUB_TOKEN:
    st.error("GitHubã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlitã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã« `github.token` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
else:
    try:
        # 0. ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼IDã‚’å–å¾—
        workflow_id = get_workflow_id_by_filename(WORKFLOW_FILENAME)

        # 1. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œå±¥æ­´ã‚’å–å¾—
        runs = get_workflow_runs(workflow_id)
        
        if not runs:
            st.warning("æˆåŠŸã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            # 2. æ—¥ä»˜é¸æŠã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            run_data = []
            for run in runs:
                run_artifacts = get_artifacts_for_run(run["id"])
                for artifact in run_artifacts:
                    if artifact["name"] == ARTIFACT_NAME and not artifact["expired"]:
                        run_data.append({
                            "display_name": f"{datetime.fromisoformat(run['created_at'].replace('Z', '+00:00')).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} (ID: {run['id']})",
                            "run_id": run["id"],
                            "artifact_url": artifact["archive_download_url"]
                        })
                        break 
            
            if not run_data:
                st.warning(f"'{ARTIFACT_NAME}' ã¨ã„ã†åå‰ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                df_runs = pd.DataFrame(run_data)

                # 3. ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã§è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã‚’é¸æŠ
                selected_run_display_name = st.selectbox(
                    "è¡¨ç¤ºã—ãŸã„ãƒ¬ãƒãƒ¼ãƒˆã®æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                    df_runs["display_name"]
                )
                
                if selected_run_display_name:
                    # 4. é¸æŠã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã®PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤º
                    selected_artifact_url = df_runs[df_runs["display_name"] == selected_run_display_name].iloc[0]["artifact_url"]
                    
                    with st.spinner("PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                        pdf_bytes = download_and_extract_pdf(selected_artifact_url)
                    
                    if pdf_bytes:
                        st.pdf(pdf_bytes, height=1000)
                    else:
                        st.error("PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã¾ãŸã¯å±•é–‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    except requests.exceptions.RequestException as e:
        st.error(f"GitHub APIã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.error(f"URL: {e.request.url}") # ãƒ‡ãƒãƒƒã‚°ç”¨ã«URLã‚’è¡¨ç¤º
    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
