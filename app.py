# app.py
import streamlit as st
import requests
import zipfile
import io
import pandas as pd
from datetime import datetime
from PIL import Image

# --- å®šæ•°è¨­å®š ---
GITHUB_API_URL = "https://api.github.com"
REPO_OWNER = "yamahei21python" 
REPO_NAME = "tamahome-scraper-daily"
WORKFLOW_FILENAME = "scheduled-scraper.yml"
ARTIFACT_NAME = "daily-analysis-report" 

try:
    GITHUB_TOKEN = st.secrets["github"]["token"]
except (KeyError, FileNotFoundError):
    import os
    GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")

HEADERS = {
    "Accept": "application/vnd.github.v3+json",
    "Authorization": f"token {GITHUB_TOKEN}",
}

st.set_page_config(page_title="ã‚¿ãƒãƒ›ãƒ¼ãƒ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ", layout="wide")
st.title("ğŸ“Š ã‚¿ãƒãƒ›ãƒ¼ãƒ  æ—¥æ¬¡åˆ†æãƒ¬ãƒãƒ¼ãƒˆãƒ“ãƒ¥ãƒ¼ã‚¢")
st.markdown(f"ãƒªãƒã‚¸ãƒˆãƒª: [{REPO_OWNER}/{REPO_NAME}](https://github.com/{REPO_OWNER}/{REPO_NAME})")

# --- é–¢æ•°å®šç¾© ---
# ... (get_workflow_id_by_filename, get_workflow_runs, get_artifacts_for_run ã¯å¤‰æ›´ãªã—) ...
@st.cache_data(ttl=86400)
def get_workflow_id_by_filename(filename: str):
    # ...
    pass

@st.cache_data(ttl=3600)
def get_workflow_runs(workflow_id: int):
    # ...
    pass

@st.cache_data(ttl=3600)
def get_artifacts_for_run(run_id):
    # ...
    pass

@st.cache_data(ttl=86400)
def download_and_extract_images(artifact_url):
    """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹"""
    response = requests.get(artifact_url, headers=HEADERS, stream=True)
    response.raise_for_status()

    images = {}
    analysis_text = ""
    with zipfile.ZipFile(io.BytesIO(response.content)) as z:
        # zipãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ«ãƒ¼ãƒ—
        for filename in sorted(z.namelist()): # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆã—ã¦é †ç•ªã‚’æ‹…ä¿
            if filename.lower().endswith(".png"):
                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                img_bytes = z.read(filename)
                images[filename] = Image.open(io.BytesIO(img_bytes))
            elif filename.lower().endswith(".txt"):
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                analysis_text = z.read(filename).decode('utf-8')
    return images, analysis_text

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
if not GITHUB_TOKEN:
    st.error("GitHubã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
else:
    try:
        workflow_id = get_workflow_id_by_filename(WORKFLOW_FILENAME)
        runs = get_workflow_runs(workflow_id)
        
        if not runs:
            st.warning("æˆåŠŸã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            run_data = []
            for run in runs:
                run_artifacts = get_artifacts_for_run(run["id"])
                for artifact in run_artifacts:
                    if artifact["name"] == ARTIFACT_NAME and not artifact["expired"]:
                        run_data.append({
                            "display_name": f"{datetime.fromisoformat(run['created_at'].replace('Z', '+00:00')).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} (ID: {run['id']})",
                            "artifact_url": artifact["archive_download_url"]
                        })
                        break 
            
            if not run_data:
                st.warning(f"'{ARTIFACT_NAME}' ã¨ã„ã†åå‰ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                df_runs = pd.DataFrame(run_data)
                selected_run_display_name = st.selectbox(
                    "è¡¨ç¤ºã—ãŸã„ãƒ¬ãƒãƒ¼ãƒˆã®æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„:",
                    df_runs["display_name"]
                )
                
                if selected_run_display_name:
                    selected_artifact_url = df_runs[df_runs["display_name"] == selected_run_display_name].iloc[0]["artifact_url"]
                    
                    with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
                        images, analysis_text = download_and_extract_images(selected_artifact_url)
                    
                    if images:
                        st.header("åˆ†æã‚°ãƒ©ãƒ•")
                        for filename, img in images.items():
                            st.image(img, caption=filename, use_column_width=True)
                        
                        if analysis_text:
                            st.header("ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆåˆ†æçµæœ")
                            st.text(analysis_text)
                    else:
                        st.error("ãƒ¬ãƒãƒ¼ãƒˆç”»åƒã®å–å¾—ã¾ãŸã¯å±•é–‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
